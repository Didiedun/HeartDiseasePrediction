# -*- coding: utf-8 -*-
"""Knn&hypertuning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zJbOqFIn4RPgkAirUOxATNdUbef-3Lm9
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

"""Data Preprocessing"""

# Read Dataset to pandas dataframe
heartdata = pd.read_csv('heart.csv')

heartdata.head()

# Assign data from first ten columns to x variable
x = heartdata.iloc[:, 0:11]

# Assign data from the eleventh column to y variable
y = heartdata.iloc[:, 11:12]

# Convert x from categorical to numerical
from sklearn import preprocessing
le = preprocessing.LabelEncoder()

y = y.apply(le.fit_transform)
x = x.apply(le.fit_transform)

# Recheck column values 
x.head()

"""**Train, Test, Split and Feature Scaling**"""

# Train, Test, Split
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20)

# Feature Scaling (Standardization)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(x_train)

x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)
print(x_test)

"""# **Artificial Neural Network (ANN)**"""

# Training and Predictions
from sklearn.neural_network import MLPClassifier
mlp = MLPClassifier(hidden_layer_sizes = (10, 10), max_iter = 2000)
mlp.fit(x_train, y_train.values.ravel())
MLPClassifier(hidden_layer_sizes = (10, 10), max_iter = 2000)

# Making Predictions
predictions = mlp.predict(x_test)

# Evaluating algorithm
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, predictions))
print(classification_report(y_test, predictions))

# Sensitivity and Specificity
recall_sensitivity = metrics.recall_score(y_test, predictions, pos_label=1)
recall_specificity = metrics.recall_score(y_test, predictions, pos_label=0)
recall_sensitivity, recall_specificity

"""# **K-Nearest Neighbors (KNN)**"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(x_train,y_train.values.ravel())
knn

prediction_knn = knn.predict(x_test)
prediction = dt.predict(x_test)
accuracy_knn = accuracy_score(y_test,prediction)*100
accuracy_knn

from sklearn import metrics
# calculating the accuracy of models with different values of k
mean_acc = np.zeros(20)
for i in range(1,21):
    #Train Model and Predict  
    knn = KNeighborsClassifier(n_neighbors = i).fit(x_train,y_train.values.ravel())
    yhat= knn.predict(x_test)
    mean_acc[i-1] = metrics.accuracy_score(y_test, yhat)

mean_acc

loc = np.arange(1,21,step=1.0)
plt.figure(figsize = (10, 6))
plt.plot(range(1,21), mean_acc)
plt.xticks(loc)
plt.xlabel('Number of Neighbors ')
plt.ylabel('Accuracy')
plt.show()

"""# **Hyperparameter Tuning**"""

from sklearn.model_selection import GridSearchCV

grid_params = { 'n_neighbors' : [5,7,9,11,13,15],
               'weights' : ['uniform','distance'],
               'metric' : ['minkowski','euclidean','manhattan']}

gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)

# fit the model on our train set
g_res = gs.fit(x_train, y_train.values.ravel())

# find the best score
g_res.best_score_

# get the hyperparameters with the best score
g_res.best_params_

# use the best hyperparameters
knn = KNeighborsClassifier(n_neighbors = 5, weights = 'uniform',algorithm = 'brute',metric = 'minkowski')
knn.fit(x_train, y_train.values.ravel())

# get a prediction
y_hat = knn.predict(x_train)
y_knn = knn.predict(x_test)

"""# **Model Evaluation**"""

print('Training set accuracy: ', metrics.accuracy_score(y_train, y_hat))
print('Test set accuracy: ',metrics.accuracy_score(y_test, y_knn))

import matplotlib
from sklearn.metrics import classification_report, confusion_matrix

# Calculate the confusion matrix
conf_matrix = confusion_matrix(y_test, predictions)

# Print the confusion matrix using Matplotlib
fig, ax = plt.subplots(figsize=(7.5, 7.5))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_test, y_knn))

# Sensitivity and Specificity
recall_sensitivity = metrics.recall_score(y_test, predictions, pos_label=1)
recall_specificity = metrics.recall_score(y_test, predictions, pos_label=0)
recall_sensitivity, recall_specificity

from sklearn.model_selection import cross_val_score
scores = cross_val_score(knn, x, y.values.ravel(), cv =3)